{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask R-CNN - Inspect Trained Model\n",
    "\n",
    "Code and visualizations to test, debug, and evaluate the Mask R-CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage.measure import find_contours\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "import IPython.display\n",
    "\n",
    "\n",
    "import utils\n",
    "import visualize\n",
    "from visualize import display_images\n",
    "import model_res18_ose as modellib\n",
    "from model import log\n",
    "%matplotlib inline \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "#Directory to save results\n",
    "RESULT_DIR = os.path.join(ROOT_DIR, \"results\")\n",
    "\n",
    "\n",
    "# Path to trained weights file\n",
    "# Download this file and place in the root of your \n",
    "# project (See README file for details)\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "CXR_MODEL_PATH = os.path.join(MODEL_DIR, \"res18_kmeans1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cxr\n",
    "config = cxr.CxrConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build validation dataset\n",
    "if config.NAME == 'shapes':\n",
    "    dataset = shapes.ShapesDataset()\n",
    "    dataset.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "elif config.NAME == \"coco\":\n",
    "    dataset = coco.CocoDataset()\n",
    "    dataset.load_coco(COCO_DIR, \"minival\")\n",
    "elif config.NAME == \"cxr\":\n",
    "    dataset = cxr.CxrDataset()\n",
    "    dataset.load_cxr(txt='/media/Disk/wangfuyu/Mask_RCNN/data/cxr/val_id.txt')\n",
    "\n",
    "    \n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)\n",
    "\n",
    "# Set weights file path\n",
    "if config.NAME == \"shapes\":\n",
    "    weights_path = SHAPES_MODEL_PATH\n",
    "elif config.NAME == \"coco\":\n",
    "    weights_path = COCO_MODEL_PATH\n",
    "elif config.NAME == \"cxr\":\n",
    "    weights_path = CXR_MODEL_PATH\n",
    "    \n",
    "# Or, uncomment to load the last model you trained\n",
    "# weights_path = model.find_last()[1]\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute IoU\n",
    "\n",
    "visual_dir = './visual/cxr'\n",
    "maskrcnn_results_dir = '/media/Disk/wangfuyu/Mask_RCNN/results_255/cxr'\n",
    "\n",
    "isExists=os.path.exists(visual_dir)\n",
    "if not isExists:\n",
    "    os.makedirs(visual_dir) \n",
    "\n",
    "isExists=os.path.exists(maskrcnn_results_dir)\n",
    "if not isExists:\n",
    "    os.makedirs(maskrcnn_results_dir) \n",
    "\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    \n",
    "    return colors\n",
    "\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "def display_instances(image, boxes, masks, class_ids, class_names,\n",
    "                      save_dir, scores=None, title=\"\",\n",
    "                      figsize=(16, 16), ax=None):\n",
    "    \"\"\"\n",
    "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
    "    masks: [height, width, num_instances]\n",
    "    class_ids: [num_instances]\n",
    "    class_names: list of class names of the dataset\n",
    "    scores: (optional) confidence scores for each box\n",
    "    figsize: (optional) the size of the image.\n",
    "    \"\"\"\n",
    "    # Number of instances\n",
    "    N = boxes.shape[0]\n",
    "    if not N:\n",
    "        print(\"\\n*** No instances to display *** \\n\")\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "\n",
    "    if not ax:\n",
    "        fig = fig = plt.figure(figsize=figsize)\n",
    "\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    # Generate random colors\n",
    "    colors = random_colors(N)\n",
    "\n",
    "    # Show area outside image boundaries.\n",
    "    height, width = image.shape[:2]\n",
    "    ax.set_ylim(height + 10, -10)\n",
    "    ax.set_xlim(-10, width + 10)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    masked_image = image.astype(np.uint32).copy()\n",
    "    for i in range(N):\n",
    "        color = colors[i]\n",
    "\n",
    "        # Bounding box\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
    "                              alpha=0.7, linestyle=\"dashed\",\n",
    "                              edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(p)\n",
    "\n",
    "        # Label\n",
    "        class_id = class_ids[i]\n",
    "        score = scores[i] if scores is not None else None\n",
    "        label = class_names[class_id]\n",
    "        x = random.randint(x1, (x1 + x2) // 2)\n",
    "        caption = \"{} {:.3f}\".format(label, score) if score else label\n",
    "        ax.text(x1, y1 + 8, caption,\n",
    "                color='w', size=11, backgroundcolor=\"none\")\n",
    "\n",
    "        # Mask\n",
    "        mask = masks[:, :, i]\n",
    "        masked_image = apply_mask(masked_image, mask, color)\n",
    "\n",
    "        # Mask Polygon\n",
    "        # Pad to ensure proper polygons for masks that touch image edges.\n",
    "        padded_mask = np.zeros(\n",
    "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        contours = find_contours(padded_mask, 0.5)\n",
    "        for verts in contours:\n",
    "            # Subtract the padding and flip (y, x) to (x, y)\n",
    "            verts = np.fliplr(verts) - 1\n",
    "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
    "            ax.add_patch(p)\n",
    "\n",
    "#     fig.savefig(save_dir)\n",
    "    return masked_image.astype(np.uint8)\n",
    "\n",
    "def _dice(y_pred, y_true):\n",
    "    smooth = 1.\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    score = (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "    return score\n",
    "\n",
    "def _fast_hist(label_pred, label_true, num_classes):\n",
    "    mask = (label_true >= 0) & (label_true < num_classes)\n",
    "    hist = np.bincount(\n",
    "        num_classes * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=num_classes ** 2).reshape(num_classes, num_classes)\n",
    "    return hist\n",
    "\n",
    "def compute_IOU(lp, lt, num_classes=2):\n",
    "    hist = np.zeros((num_classes, num_classes))\n",
    "    hist += _fast_hist(lp.flatten(), lt.flatten(), num_classes)\n",
    "    dice = _dice(y_pred=lp, y_true=lt)\n",
    "    # axis 0: gt, axis 1: prediction\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "    # mean_iu = np.nanmean(iu)\n",
    "    freq = hist.sum(axis=1) / hist.sum()\n",
    "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "\n",
    "    return acc, acc_cls, iu, fwavacc, dice\n",
    "\n",
    "\n",
    "# Compute VOC-style Average Precision\n",
    "def compute_batch_ap(image_ids, iou_threshold=0.5):\n",
    "    APs = []\n",
    "    txt = open('res18_kmeans2.txt', 'w')\n",
    "    \n",
    "    txt.write('filename' + ' ' + 'image_id' + ' ' + 'iu' + ' ' + 'dice' + '\\n')\n",
    "    \n",
    "#     images_dir = '/media/Disk/wangfuyu/Mask_RCNN/data/cxr/1024/images'\n",
    "#     masks255_dir = '/media/Disk/wangfuyu/Mask_RCNN/data/cxr/1024/masks255'\n",
    "#     isExists=os.path.exists(images_dir)\n",
    "#     if not isExists:\n",
    "#         os.makedirs(images_dir)  \n",
    "    \n",
    "#     isExists=os.path.exists(masks255_dir)\n",
    "#     if not isExists:\n",
    "#         os.makedirs(masks255_dir)\n",
    "\n",
    "    \n",
    "    iu, dice = np.zeros(len(image_ids)), np.zeros(len(image_ids))\n",
    "    iu_normal, iu_abnormal = [], []\n",
    "    dice_normal, dice_abnormal = [], []\n",
    "    for index, image_id in enumerate(image_ids):\n",
    "        # Load image\n",
    "        image, image_meta, row_wave, col_wave, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset, config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "        \n",
    "#         info = dataset.image_info[image_id]\n",
    "#         filename = info['filename']\n",
    "#         cv2.imwrite(os.path.join(images_dir, filename + '.jpg'), image, \n",
    "#                     [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "#         gt_mask = np.sum(gt_mask, axis=2) \n",
    "#         gt_mask *= 255\n",
    "#         cv2.imwrite(os.path.join(masks255_dir, filename + '.png'), gt_mask, \n",
    "#                     [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "#         print(filename)\n",
    "    \n",
    "        \n",
    "        # Run object detection\n",
    "        results = model.detect([image], np.stack([row_wave]), np.stack([col_wave]), verbose=0)\n",
    "#         results = model.detect([image], verbose=0)\n",
    "\n",
    "        \n",
    "        # Compute AP\n",
    "        r = results[0]\n",
    "        AP, precisions, recalls, overlaps =\\\n",
    "            utils.compute_ap(gt_bbox, gt_class_id,\n",
    "                              r['rois'], r['class_ids'], r['scores'], iou_threshold)\n",
    "            \n",
    "        APs.append(AP)\n",
    "        \n",
    "        info = dataset.image_info[image_id]\n",
    "        filename = info['filename']\n",
    "        \n",
    "\n",
    "#         display_instances(image, r['rois'], r['masks'], r['class_ids'], dataset.class_names, \n",
    "#                           os.path.join(visual_dir, filename + '.png'), \n",
    "#                           r['scores'], title=\"Predictions\")\n",
    "\n",
    "#         masked_image = display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "#                                          dataset.class_names, \n",
    "#                                          os.path.join(visual_dir, filename + '.png'), \n",
    "#                                          r['scores'], title=\"Predictions\")\n",
    "#         cv2.imwrite(os.path.join(visual_dir, filename + '.png'), masked_image, [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "\n",
    "            \n",
    "        shape = r['masks'].shape\n",
    "        pred_mask = np.zeros((1024, 1024))\n",
    "        \n",
    "        pred_mask = pred_mask.astype(np.int64)\n",
    "        r['masks'] = r['masks'].astype(np.int64)\n",
    "        \n",
    "        \n",
    "        if shape[0] == 1024:    \n",
    "            for i in range(shape[2]):\n",
    "                pred_mask = np.bitwise_or(pred_mask, r['masks'][:,:,i])\n",
    "\n",
    "\n",
    "        gt_mask = np.sum(gt_mask, axis=2)        \n",
    "#         print (pred_mask.shape, gt_mask.shape, shape)\n",
    "        \n",
    "        \n",
    "#         plt.figure(figsize=(20,20))\n",
    "#         plt.subplot(2, 1, 1),\n",
    "#         plt.imshow(gt_mask)\n",
    "#         plt.subplot(2, 1, 2)\n",
    "#         plt.imshow(pred_mask)\n",
    "#         plt.show()\n",
    "        \n",
    "        evals = compute_IOU(pred_mask, gt_mask)\n",
    "        iu[index] = evals[2][1]\n",
    "        dice[index] = evals[4]\n",
    "        if (filename[0:2] == 'CA'):\n",
    "            iu_abnormal.append(iu[index])\n",
    "            dice_abnormal.append(dice[index])\n",
    "        else:\n",
    "            iu_normal.append(iu[index])\n",
    "            dice_normal.append(dice[index])\n",
    "\n",
    "        \n",
    "        print(filename, image_id, iu[index])\n",
    "        txt.write(filename + ' ' + str(image_id) + ' ' + str(iu[index])[0:8] \n",
    "                  + ' ' + str(dice[index])[0:8] + '\\n')\n",
    "        filename = filename + '_' + str(iu[index])[0:8]\n",
    "#         cv2.imwrite(os.path.join(maskrcnn_results_dir, filename + '.png'), (pred_mask*255).astype(np.uint8), [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "    \n",
    "    iu_abnormal = np.stack(iu_abnormal)\n",
    "    iu_normal = np.stack(iu_normal)\n",
    "    dice_abnormal = np.stack(dice_abnormal)\n",
    "    dice_normal = np.stack(dice_normal)\n",
    "    print(iu.mean(), iu.std(), dice.mean(), dice.std())\n",
    "#     print(iu_abnormal.shape, iu_abnormal.mean(), iu_normal.shape, iu_normal.mean())    \n",
    "    txt.write('iu.mean ' + str(iu.mean())[0:8] + \n",
    "              ' iu_abnormal ' + str(iu_abnormal.mean())[0:8] + \n",
    "              ' iu_normal ' + str(iu_normal.mean())[0:8] + '\\n')\n",
    "    txt.write('dice.mean ' + str(dice.mean())[0:8] + \n",
    "              ' dice_abnormal ' + str(dice_abnormal.mean())[0:8] + \n",
    "              ' dice_normal ' + str(dice_normal.mean())[0:8] + '\\n')\n",
    "    txt.write('iu.mean ' + str(iu.mean())[0:8] + 'iu.std' + str(iu.std())[0:8] + '\\n')\n",
    "    txt.write('dice.mean ' + str(dice.mean())[0:8] + 'dice.std' + str(dice.std())[0:8] + '\\n')\n",
    "    return APs\n",
    "\n",
    "# Pick a set of random images\n",
    "image_ids = np.random.choice(dataset.image_ids, 10)\n",
    "APs = compute_batch_ap(dataset.image_ids, iou_threshold=0.5)\n",
    "print(\"mAP @ IoU=80: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images_dir = '/media/Disk/wangfuyu/Mask_RCNN/crop_results/cxr/res18_ose_kmeans1/512_320/images/'\n",
    "mrcnn_masks_dir = '/media/Disk/wangfuyu/Mask_RCNN/crop_results/cxr/res18_ose_kmeans1/512_320/mrcnn_masks/'\n",
    "masks_dir = '/media/Disk/wangfuyu/Mask_RCNN/crop_results/cxr/res18_ose_kmeans1/512_320/masks/'\n",
    "\n",
    "\n",
    "isExists=os.path.exists(images_dir)\n",
    "if not isExists:\n",
    "    os.makedirs(images_dir) \n",
    "\n",
    "isExists=os.path.exists(mrcnn_masks_dir)\n",
    "if not isExists:\n",
    "    os.makedirs(mrcnn_masks_dir) \n",
    "    \n",
    "isExists=os.path.exists(masks_dir)\n",
    "if not isExists:\n",
    "    os.makedirs(masks_dir) \n",
    "\n",
    "# train_txt = open('/media/Disk/wangfuyu/Mask_RCNN/crop_results/cxr/res18_ose_kmeans1/512_320/train_id.txt', 'w')\n",
    "# val_txt = open('/media/Disk/wangfuyu/Mask_RCNN/crop_results/cxr/res18_ose_kmeans1/512_320/val_id.txt', 'w')\n",
    "# val_box_info = open('/media/Disk/wangfuyu/Mask_RCNN/crop_results/cxr/res18_ose_kmeans1/512_320/box_info.txt', 'w')    \n",
    "\n",
    "\n",
    "def _dice(y_pred, y_true):\n",
    "    smooth = 1.\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    score = (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "    return score\n",
    "\n",
    "def _fast_hist(label_pred, label_true, num_classes):\n",
    "    mask = (label_true >= 0) & (label_true < num_classes)\n",
    "    hist = np.bincount(\n",
    "        num_classes * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=num_classes ** 2).reshape(num_classes, num_classes)\n",
    "    return hist\n",
    "\n",
    "def compute_IOU(lp, lt, num_classes=2):\n",
    "    hist = np.zeros((num_classes, num_classes))\n",
    "    hist += _fast_hist(lp.flatten(), lt.flatten(), num_classes)\n",
    "    dice = _dice(y_pred=lp, y_true=lt)\n",
    "    # axis 0: gt, axis 1: prediction\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "    # mean_iu = np.nanmean(iu)\n",
    "    freq = hist.sum(axis=1) / hist.sum()\n",
    "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "\n",
    "    return acc, acc_cls, iu, fwavacc, dice\n",
    "\n",
    "    \n",
    "\n",
    "# Compute VOC-style Average Precision\n",
    "def compute_batch_ap(image_ids, iou_threshold=0.5):\n",
    "    APs = []\n",
    "    IMAGE_MIN_DIM = 320\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    iu = np.zeros(len(image_ids))\n",
    "    for index, image_id in enumerate(image_ids):\n",
    "        # Load image\n",
    "        image, image_meta, row_wave, col_wave, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset, config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "        # Run object detection\n",
    "        mrcnn_results = model.detect([image], np.stack([row_wave]), np.stack([col_wave]), verbose=0)\n",
    "            \n",
    "        \n",
    "        info = dataset.image_info[image_id]\n",
    "        filename = info['filename']\n",
    "#         filename = info['filename'][0:-4]    ##JSRT\n",
    "        \n",
    "        \n",
    "        mrcnn_result = mrcnn_results[0]\n",
    "\n",
    "\n",
    "        for i in range(gt_mask.shape[2]):\n",
    "            max_iou = 0.\n",
    "            final_index = 0    ## left or right lung\n",
    "#             print(gt_bbox.shapey)\n",
    "            y1, x1, y2, x2 = 0, 0, 0, 0\n",
    "            for j in range(mrcnn_result['masks'].shape[2]):\n",
    "                iou = compute_IOU(mrcnn_result['masks'][:,:,j], gt_mask[:,:,i])\n",
    "                if max_iou < iou[2][1]:\n",
    "                    max_iou = iou[2][1]\n",
    "                    final_index = j\n",
    "                    y1, x1, y2, x2 = mrcnn_result['rois'][j]\n",
    "\n",
    "                        \n",
    "            \n",
    "            y1 = max(y1 - int((y2 - y1) * 0.25), 0)\n",
    "            x1 = max(x1 - int((x2 - x1) * 0.25), 0)\n",
    "            y2 = min(y2 + int((y2 - y1) * 0.25), 1024)\n",
    "            x2 = min(x2 + int((x2 - x1) * 0.25), 1024)\n",
    "            \n",
    "            \n",
    "#             print (gt_mask.shape)\n",
    "\n",
    "            crop_image = image[y1:y2, x1:x2, :]\n",
    "            crop_mask = gt_mask[y1:y2, x1:x2, i] \n",
    "            crop_mrcnn_mask = mrcnn_result['masks'][y1:y2, x1:x2, final_index]\n",
    "\n",
    "\n",
    "#             crop_image = cv2.resize(crop_image.astype(np.uint8), (IMAGE_MIN_DIM, IMAGE_MAX_DIM),\n",
    "#                                     interpolation=cv2.INTER_LINEAR)\n",
    "#             crop_mask = cv2.resize(crop_mask.astype(np.uint8), (IMAGE_MIN_DIM, IMAGE_MAX_DIM),\n",
    "#                                    interpolation=cv2.INTER_LINEAR)\n",
    "#             crop_mrcnn_mask = cv2.resize(crop_mrcnn_mask.astype(np.uint8), (IMAGE_MIN_DIM, IMAGE_MAX_DIM),\n",
    "#                                          interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            \n",
    "#             plt.figure(figsize=(20,20))\n",
    "#             plt.subplot(3,1,1)\n",
    "#             plt.imshow(crop_image)\n",
    "#             plt.subplot(3,1,2)\n",
    "#             plt.imshow(crop_mask)\n",
    "#             plt.subplot(3,1,3)\n",
    "#             plt.imshow(crop_mrcnn_mask)\n",
    "#             plt.show()\n",
    "            \n",
    "            savename = filename + '_' + str(i)\n",
    "            print(savename + ' ' + str(y1) + ' ' + str(x1) + ' ' + str(y2) + ' ' + str(x2))\n",
    "\n",
    "#             val_box_info.write(savename + ' ' + str(y1) + ' ' + str(x1) + \n",
    "#                                ' ' + str(y2) + ' ' + str(x2) + '\\n')\n",
    "#             cv2.imwrite(images_dir + savename + '.jpg', crop_image, \n",
    "#                         [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "            \n",
    "#             cv2.imwrite(masks_dir + savename + '.png', crop_mask, \n",
    "#                         [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "            \n",
    "#             cv2.imwrite(mrcnn_masks_dir + savename + '.png', crop_mrcnn_mask, \n",
    "#                         [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "            \n",
    "#             val_txt.write(savename + '\\n')\n",
    "#             print(savename)\n",
    "#             train_txt.write(savename + '\\n')\n",
    "\n",
    "            \n",
    "\n",
    "# Pick a set of random images\n",
    "\n",
    "compute_batch_ap(dataset.image_ids, iou_threshold=0.5)\n",
    "# for image_id in dataset.image_ids:\n",
    "#     print(image_id, dataset.image_info[image_id]['filename'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute IoU\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gt_mask_dir = '/media/Disk/wangfuyu/Mask_RCNN/data/cxr/binary_masks/'\n",
    "back_mask_dir = '/media/Disk/wangfuyu/Mask_RCNN/refine/HED/cxr/res18_ose_kmeans1/512_320/back/'\n",
    "iou_dir = '/media/Disk/wangfuyu/Mask_RCNN/refine/HED/cxr/res18_ose_kmeans1/512_320/iou/'\n",
    "txt = open('/media/Disk/wangfuyu/Mask_RCNN/refine/HED/cxr/res18_ose_kmeans1/512_320/record.txt', 'w')\n",
    "\n",
    "# gt_mask_dir = '/media/Disk/wangfuyu/Mask_RCNN/data/cxr/800/JSRT/binary_masks/'\n",
    "# back_mask_dir = '/media/Disk/wangfuyu/Mask_RCNN/unet/results/crop_preserve/JSRT/800/renet_C5_wave/512_320/back/'\n",
    "# iou_dir = '/media/Disk/wangfuyu/Mask_RCNN/unet/results/crop_preserve/JSRT/800/renet_C5_wave/512_320/iou/'\n",
    "# txt = open('/media/Disk/wangfuyu/Mask_RCNN/unet/results/crop_preserve/JSRT/800/renet_C5_wave/512_320/record.txt', 'w')\n",
    "\n",
    "isExists=os.path.exists(iou_dir)\n",
    "if not isExists:\n",
    "    os.makedirs(iou_dir) \n",
    "\n",
    "def _dice(y_pred, y_true):\n",
    "    smooth = 1.\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    score = (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "    return score\n",
    "\n",
    "def _fast_hist(label_pred, label_true, num_classes):\n",
    "    mask = (label_true >= 0) & (label_true < num_classes)\n",
    "    hist = np.bincount(\n",
    "        num_classes * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=num_classes ** 2).reshape(num_classes, num_classes)\n",
    "    return hist\n",
    "\n",
    "def compute_IOU(lp, lt, num_classes=2):\n",
    "    hist = np.zeros((num_classes, num_classes))\n",
    "    hist += _fast_hist(lp.flatten(), lt.flatten(), num_classes)\n",
    "    dice = _dice(y_pred=lp, y_true=lt)\n",
    "    # axis 0: gt, axis 1: prediction\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "    # mean_iu = np.nanmean(iu)\n",
    "    freq = hist.sum(axis=1) / hist.sum()\n",
    "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "\n",
    "    return acc, acc_cls, iu, fwavacc, dice\n",
    "\n",
    "\n",
    "# Compute VOC-style Average Precision\n",
    "def compute_batch_ap(image_ids):    \n",
    "    txt.write('filename' + ' ' + 'image_id' + ' ' + 'iu' + ' ' + 'dice' + '\\n')\n",
    "    \n",
    "    iu, dice = np.zeros(len(image_ids)), np.zeros(len(image_ids))\n",
    "    iu_normal, iu_abnormal = [], []\n",
    "    dice_normal, dice_abnormal = [], []\n",
    "\n",
    "    for index, image_id in enumerate(image_ids):\n",
    "        # Load image\n",
    "        image, image_meta, _, _, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset, config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "\n",
    "        gt_mask = np.sum(gt_mask, axis=2)\n",
    "        \n",
    "        info = dataset.image_info[image_id]\n",
    "        filename = info['filename']\n",
    "#         filename = info['filename'][0:-4]   ## JSRT\n",
    "\n",
    "#         print(filename)\n",
    "        back = cv2.imread(back_mask_dir + filename + '.png', cv2.COLOR_BGR2GRAY)\n",
    "        _, back_mask = cv2.threshold(back, 127, 1, cv2.THRESH_BINARY)\n",
    "        \n",
    "\n",
    "        \n",
    "#         plt.figure(figsize=(20,20))\n",
    "#         plt.subplot(2, 1, 1),\n",
    "#         plt.imshow(gt_mask)\n",
    "#         plt.subplot(2, 1, 2)\n",
    "#         plt.imshow(back_mask)\n",
    "#         plt.show()\n",
    "#             print (compute_IOU(predictions, gts)[2][1])\n",
    "        print(back_mask.shape, gt_mask.shape)\n",
    "        evals = compute_IOU(back_mask, gt_mask)\n",
    "        iu[index] = evals[2][1]\n",
    "        dice[index] = evals[4]\n",
    "        if (filename[0:2] == 'CA'):\n",
    "            iu_abnormal.append(iu[index])\n",
    "            dice_abnormal.append(dice[index])\n",
    "        else:\n",
    "            iu_normal.append(iu[index])\n",
    "            dice_normal.append(dice[index])\n",
    "        print(filename, iu[index])\n",
    "        \n",
    "        savename = filename + '_' + str(iu[index])[0:8]\n",
    "        txt.write(filename + ' ' + str(image_id) + ' ' + str(iu[index])[0:8] \n",
    "                  + ' ' + str(dice[index])[0:8] + '\\n')\n",
    "        cv2.imwrite(os.path.join(iou_dir, savename + '.png'), back, \n",
    "                    [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
    "            \n",
    "#     iu_abnormal = np.stack(iu_abnormal)\n",
    "#     iu_normal = np.stack(iu_normal)\n",
    "#     dice_abnormal = np.stack(dice_abnormal)\n",
    "#     dice_normal = np.stack(dice_normal)\n",
    "    print(iu.mean(), iu.std(), dice.mean(), dice.std())\n",
    "#     print(iu_abnormal.shape, iu_abnormal.mean(), iu_normal.shape, iu_normal.mean())\n",
    "    #     print(iu_abnormal.shape, iu_abnormal.mean(), iu_normal.shape, iu_normal.mean()) \n",
    "#     txt.write('iu.mean ' + str(iu.mean())[0:8] + \n",
    "#               ' iu_abnormal ' + str(iu_abnormal.mean())[0:8] + \n",
    "#               ' iu_normal ' + str(iu_normal.mean())[0:8] + '\\n')\n",
    "#     txt.write('dice.mean ' + str(dice.mean())[0:8] + \n",
    "#               ' dice_abnormal ' + str(dice_abnormal.mean())[0:8] + \n",
    "#               ' dice_normal ' + str(dice_normal.mean())[0:8] + '\\n')\n",
    "    txt.write('iu.mean ' + str(iu.mean())[0:8] + ' ' + str(iu.std())[0:8] + '\\n')\n",
    "    txt.write('dice.mean ' + str(dice.mean())[0:8] + ' ' + str(dice.mean())[0:8] + '\\n')\n",
    "\n",
    "compute_batch_ap(dataset.image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute IoU\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gt_mask_dir = '/media/Disk/wangfuyu/Mask_RCNN/crop_results/cxr/res18_ose_kmeans1/512_320/masks/'\n",
    "box_mask_dir = '/media/Disk/wangfuyu/Mask_RCNN/refine/HED/cxr/res18_ose_kmeans1/512_320/Segresult/'\n",
    "\n",
    "\n",
    "def _dice(y_pred, y_true):\n",
    "    smooth = 1.\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    score = (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "    return score\n",
    "\n",
    "def _fast_hist(label_pred, label_true, num_classes):\n",
    "    mask = (label_true >= 0) & (label_true < num_classes)\n",
    "    hist = np.bincount(\n",
    "        num_classes * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=num_classes ** 2).reshape(num_classes, num_classes)\n",
    "    return hist\n",
    "\n",
    "def compute_IOU(lp, lt, num_classes=2):\n",
    "    hist = np.zeros((num_classes, num_classes))\n",
    "    hist += _fast_hist(lp.flatten(), lt.flatten(), num_classes)\n",
    "    dice = _dice(y_pred=lp, y_true=lt)\n",
    "    # axis 0: gt, axis 1: prediction\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "    # mean_iu = np.nanmean(iu)\n",
    "    freq = hist.sum(axis=1) / hist.sum()\n",
    "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "\n",
    "    return acc, acc_cls, iu, fwavacc, dice\n",
    "\n",
    "\n",
    "# Compute VOC-style Average Precision\n",
    "def compute_batch_ap():    \n",
    "    \n",
    "    iu, dice = [], []\n",
    "    \n",
    "    for filename in os.listdir(box_mask_dir):\n",
    "#         filename.sort()\n",
    "        print (filename)\n",
    "        gt_mask = cv2.imread(gt_mask_dir + filename, cv2.COLOR_BGR2GRAY)\n",
    "        box = cv2.imread(box_mask_dir + filename, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        print(gt_mask.shape, box.shape)\n",
    "        _, box_mask = cv2.threshold(box, 127, 1, cv2.THRESH_BINARY)\n",
    "            \n",
    "            \n",
    "        evals = compute_IOU(box_mask, gt_mask)\n",
    "        iu.append(evals[2][1])\n",
    "        dice.append(evals[4])\n",
    "            \n",
    "        print (filename, evals[2][1])   \n",
    "        \n",
    "    \n",
    "    iu = np.stack(iu)\n",
    "    print(iu.mean())\n",
    "        \n",
    "\n",
    "compute_batch_ap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
